{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "aIhjLR2OoKwN",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import glob\n",
    "import torch\n",
    "import pandas as pd\n",
    "import gc\n",
    "from os.path import join as join_path\n",
    "from PIL import Image\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 258,
     "status": "ok",
     "timestamp": 1678645276679,
     "user": {
      "displayName": "Даниил Константинов",
      "userId": "01997835485140301621"
     },
     "user_tz": -180
    },
    "id": "F5hvIQhhDib_",
    "outputId": "e41c57f0-3b6c-444b-cc57-553db20267b5",
    "tags": []
   },
   "outputs": [],
   "source": [
    "PATH_TO_FOLDER = '/iraa/main'\n",
    "\n",
    "device = torch.device('cuda:3' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8BJkjGuL64iM"
   },
   "source": [
    "# Init model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.chdir(join_path(PATH_TO_FOLDER, 'adversarial_attacks', 'facpa'))\n",
    "from cnn_attack_inference import UnetGenerator, normalize_and_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def add_delta_cnn(image: torch.tensor, delta_im, h, w, C=10):\n",
    "    delta_im = normalize_and_scale(delta_im, C) \n",
    "    delta_im = delta_im.squeeze().data.cpu().numpy().transpose(1, 2, 0) \n",
    "    delta = np.tile(delta_im,(image.shape[0] // h + 1, image.shape[1] // w + 1, 1))[:image.shape[0], :image.shape[1], :]\n",
    "    out = image + delta\n",
    "    out[out > 1] = 1\n",
    "    out[out < 0] = 0\n",
    "    res_img = (out * 255).astype('uint8')\n",
    "    return res_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "RESIZE_PARAM = 256\n",
    "\n",
    "cnn_resize = transforms.Resize((512, 1024))\n",
    "cnn_resize_256 = transforms.Resize((256))\n",
    "to_tensor = transforms.ToTensor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h3pQc5eElocK"
   },
   "source": [
    "# Run IQA models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10206"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_images = sorted(glob.glob(join_path(PATH_TO_FOLDER, 'data', 'KADID10K/kadid10k/images', '*')))\n",
    "len(all_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "egsXTvs2lvg0",
    "tags": []
   },
   "source": [
    "## Linearity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.transforms.functional import resize, to_tensor, normalize\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "netG = UnetGenerator(3, 3, 64, norm_type='instance', act_type='relu').to(device)\n",
    "netG.load_state_dict(torch.load(join_path(PATH_TO_FOLDER, 'adversarial_attacks', 'facpa', 'weigths', 'unet_lin.pth'), map_location=device))\n",
    "netG.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "EegPYDnsl3x6",
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.chdir(join_path(PATH_TO_FOLDER, 'nr_iqa_metrics', 'Linearity'))\n",
    "from IQAmodel import IQAModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gPvG2eNpl8Xp",
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = IQAModel().to(device)\n",
    "model_path = '/home/jovyan/storage/NR-metric-models/p1q2.pth'\n",
    "checkpoint = torch.load(model_path)\n",
    "k = checkpoint['k']\n",
    "b = checkpoint['b']\n",
    "model.load_state_dict(checkpoint['model'])\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 227,
     "status": "ok",
     "timestamp": 1677619233282,
     "user": {
      "displayName": "Даниил Константинов",
      "userId": "01997835485140301621"
     },
     "user_tz": -180
    },
    "id": "8L9LEoxjmJER",
    "outputId": "379c6831-63f5-4c9d-f58a-4957bc07b935",
    "tags": []
   },
   "outputs": [],
   "source": [
    "C = 22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|███                                                                                                                                                                                                                                                                 | 118/10206 [08:17<12:08:16,  4.33s/it]"
     ]
    }
   ],
   "source": [
    "res = []\n",
    "gains = []\n",
    "for image_file in tqdm(all_images):\n",
    "    im = Image.open(image_file).convert('RGB')\n",
    "    im = resize(im, (498, 664))\n",
    "    im = to_tensor(im).to(device)\n",
    "    im = normalize(im, [0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) \n",
    "    with torch.no_grad():\n",
    "        y = model(im.unsqueeze(0))[-1].cpu().detach().item()\n",
    "        before_score = y * k[-1] + b[-1]\n",
    "    \n",
    "    im = cv2.imread(image_file)\n",
    "    im = cv2.cvtColor(im, cv2.COLOR_BGR2RGB)\n",
    "    im = im.astype('float32') / 255.\n",
    "    \n",
    "    h, w = im.shape[0] // RESIZE_PARAM, im.shape[1] // RESIZE_PARAM\n",
    "    if h == 0 or w == 0:\n",
    "        image = cnn_resize_256(transforms.ToTensor()(im))\n",
    "        h, w = image.shape[1] // RESIZE_PARAM, image.shape[2] // RESIZE_PARAM\n",
    "        h, w = h * RESIZE_PARAM, w * RESIZE_PARAM\n",
    "        image = image[:, :h, :w]\n",
    "    else:\n",
    "        h, w = h * RESIZE_PARAM, w * RESIZE_PARAM\n",
    "\n",
    "        im64 = im[:h, :w, :]\n",
    "        image = transforms.ToTensor()(im64)\n",
    "   \n",
    "    delta_im = netG(image.unsqueeze(0).to(device))\n",
    "    image_after_attack = add_delta_cnn(im, delta_im, h, w, C=C)\n",
    "    \n",
    "    im_pil = Image.fromarray(cv2.cvtColor(image_after_attack, cv2.COLOR_BGR2RGB))\n",
    "    im = im_pil.convert('RGB')\n",
    "    im = resize(im, (498, 664))\n",
    "    im = to_tensor(im).to(device)\n",
    "    im = normalize(im, [0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) \n",
    "    with torch.no_grad():\n",
    "        y = model(im.unsqueeze(0))[-1].cpu().detach().item()\n",
    "        after_score = y * k[-1] + b[-1]\n",
    "    \n",
    "    gains.append([before_score, after_score])\n",
    "    res.append([image_file.split('/')[-1], before_score, after_score])\n",
    "gains = np.array(gains)\n",
    "\n",
    "df = pd.DataFrame(res, columns=['image_name', 'before_score', 'after_score'])\n",
    "df['attack_type'] = f'cnn_{C}_255'\n",
    "df['metric'] = 'lin'\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aSDjjWOjv3--",
    "tags": []
   },
   "source": [
    "## Paq-2-Piq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "netG = UnetGenerator(3, 3, 64, norm_type='instance', act_type='relu').to(device)\n",
    "netG.load_state_dict(torch.load(join_path(PATH_TO_FOLDER, 'adversarial_attacks', 'facpa', 'weigths', 'unet_p2p.pth'), map_location=device))\n",
    "netG.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.environ['my_device'] = str(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 621,
     "status": "ok",
     "timestamp": 1677617881874,
     "user": {
      "displayName": "Даниил Константинов",
      "userId": "01997835485140301621"
     },
     "user_tz": -180
    },
    "id": "-jbQZwUtv7cc",
    "outputId": "43f44962-1472-43ea-976d-520eb19fada9",
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.chdir(join_path(PATH_TO_FOLDER, 'nr_iqa_metrics', 'Paq-2-Piq'))\n",
    "from paq2piq_standalone import InferenceModel, RoIPoolModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_path = join_path(PATH_TO_FOLDER, 'nr_iqa_metrics', 'Paq-2-Piq', 'RoIPoolModel.pth')\n",
    "model = InferenceModel(RoIPoolModel().to(device), model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o_v407QJweKZ",
    "tags": []
   },
   "outputs": [],
   "source": [
    "C = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 262916,
     "status": "ok",
     "timestamp": 1677618282653,
     "user": {
      "displayName": "Даниил Константинов",
      "userId": "01997835485140301621"
     },
     "user_tz": -180
    },
    "id": "XKBO4LwVwSKm",
    "outputId": "0c490446-0f56-4270-8fec-26c352bf11c1",
    "tags": []
   },
   "outputs": [],
   "source": [
    "res = []\n",
    "gains = []\n",
    "for image_file in tqdm(all_images):\n",
    "    im = cv2.imread(image_file)\n",
    "    im = cv2.cvtColor(im, cv2.COLOR_BGR2RGB)\n",
    "    before_score = model.predict(im)['global_score']\n",
    "    im = im.astype('float32') / 255.\n",
    "    \n",
    "    h, w = im.shape[0] // RESIZE_PARAM, im.shape[1] // RESIZE_PARAM\n",
    "    if h == 0 or w == 0:\n",
    "        image = cnn_resize_256(transforms.ToTensor()(im))\n",
    "        h, w = image.shape[1] // RESIZE_PARAM, image.shape[2] // RESIZE_PARAM\n",
    "        h, w = h * RESIZE_PARAM, w * RESIZE_PARAM\n",
    "        image = image[:, :h, :w]\n",
    "    else:\n",
    "        h, w = h * RESIZE_PARAM, w * RESIZE_PARAM\n",
    "\n",
    "        im64 = im[:h, :w, :]\n",
    "        image = transforms.ToTensor()(im64)\n",
    "   \n",
    "    delta_im = netG(image.unsqueeze(0).to(device))\n",
    "    image_after_attack = add_delta_cnn(im, delta_im, h, w, C=C)\n",
    "    after_score = model.predict(image_after_attack)['global_score']\n",
    "    gains.append([before_score, after_score])\n",
    "    res.append([image_file.split('/')[-1], before_score, after_score])\n",
    "gains = np.array(gains)\n",
    "\n",
    "df = pd.DataFrame(res, columns=['image_name', 'before_score', 'after_score'])\n",
    "df['attack_type'] = f'cnn_{C}_255'\n",
    "df['metric'] = 'p2p'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ptVXOzzqv7ht",
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k3Aoflsw7ONA",
    "tags": []
   },
   "source": [
    "## SPAQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SKeDKuMs7tHv",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import torchvision\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 597,
     "status": "ok",
     "timestamp": 1677619829560,
     "user": {
      "displayName": "Даниил Константинов",
      "userId": "01997835485140301621"
     },
     "user_tz": -180
    },
    "id": "EThFy5I26bpB",
    "outputId": "f1f06aa4-c6da-4a96-db1a-e5c62c312208",
    "tags": []
   },
   "outputs": [],
   "source": [
    "netG = UnetGenerator(3, 3, 64, norm_type='instance', act_type='relu').to(device)\n",
    "netG.load_state_dict(torch.load(join_path(PATH_TO_FOLDER, 'adversarial_attacks', 'facpa', 'weigths', 'unet_spaq.pth'), map_location=device))\n",
    "netG.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H0VbzDeJ7PZY",
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.chdir(join_path(PATH_TO_FOLDER, 'nr_iqa_metrics', 'SPAQ'))\n",
    "\n",
    "from Prepare_image import Image_load\n",
    "\n",
    "\n",
    "class Baseline(torch.nn.Module):\n",
    "\tdef __init__(self):\n",
    "\t\tsuper(Baseline, self).__init__()\n",
    "\t\tself.backbone = torchvision.models.resnet50(pretrained=False)\n",
    "\t\tfc_feature = self.backbone.fc.in_features\n",
    "\t\tself.backbone.fc = torch.nn.Linear(fc_feature, 1, bias=True)\n",
    "\n",
    "\tdef forward(self, x):\n",
    "\t\tresult = self.backbone(x)\n",
    "\t\treturn result\n",
    "\n",
    "model = Baseline()\n",
    "\n",
    "model_path = '/home/jovyan/storage/NR-metric-models/BL_release.pt'\n",
    "\n",
    "checkpoint = torch.load(model_path, device)\n",
    "model.load_state_dict(checkpoint['state_dict'])\n",
    "model.to(device);\n",
    "model.eval();\n",
    "\n",
    "prepare_image = Image_load(size=512, stride=224)\n",
    "\n",
    "to_tensor = transforms.ToTensor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 232,
     "status": "ok",
     "timestamp": 1677621867351,
     "user": {
      "displayName": "Даниил Константинов",
      "userId": "01997835485140301621"
     },
     "user_tz": -180
    },
    "id": "YdIc6Wep8Dxn",
    "outputId": "90ba54c9-9fc1-4fe0-db60-f6daf66484bf",
    "tags": []
   },
   "outputs": [],
   "source": [
    "C = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "res = []\n",
    "gains = []\n",
    "for image_file in tqdm(all_images):\n",
    "    try:\n",
    "        img = prepare_image(Image.open(image_file).convert('RGB')).to(device)\n",
    "    except:\n",
    "        res.append([image_file.split('/')[-1], -1, -1])\n",
    "        continue\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        before_score = model(img).mean().detach().cpu().item()\n",
    "    \n",
    "    im = cv2.imread(image_file)\n",
    "    im = im.astype('float32') / 255.\n",
    "    \n",
    "    h, w = im.shape[0] // RESIZE_PARAM, im.shape[1] // RESIZE_PARAM\n",
    "    if h == 0 or w == 0:\n",
    "        image = cnn_resize_256(transforms.ToTensor()(im))\n",
    "        h, w = image.shape[1] // RESIZE_PARAM, image.shape[2] // RESIZE_PARAM\n",
    "        h, w = h * RESIZE_PARAM, w * RESIZE_PARAM\n",
    "        image = image[:, :h, :w]\n",
    "    else:\n",
    "        h, w = h * RESIZE_PARAM, w * RESIZE_PARAM\n",
    "\n",
    "        im64 = im[:h, :w, :]\n",
    "        image = transforms.ToTensor()(im64)\n",
    "   \n",
    "    delta_im = netG(image.unsqueeze(0).to(device))\n",
    "    image_after_attack = add_delta_cnn(im, delta_im, h, w, C=C)\n",
    "    \n",
    "    img = prepare_image(Image.fromarray(image_after_attack).convert('RGB')).to(device)\n",
    "    with torch.no_grad():\n",
    "        after_score = model(img).mean().detach().cpu().item()\n",
    "    \n",
    "    gains.append([before_score, after_score])\n",
    "    res.append([image_file.split('/')[-1], before_score, after_score])\n",
    "gains = np.array(gains)\n",
    "\n",
    "df = pd.DataFrame(res, columns=['image_name', 'before_score', 'after_score'])\n",
    "df['attack_type'] = f'cnn_{C}_255'\n",
    "df['metric'] = 'spaq'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V7zwfXNg2NGo",
    "tags": []
   },
   "source": [
    "## KonCept512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from PIL import Image\n",
    "import argparse\n",
    "import os\n",
    "from torchvision.transforms import ToTensor, Resize, Normalize\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "netG = UnetGenerator(3, 3, 64, norm_type='instance', act_type='relu').to(device)\n",
    "netG.load_state_dict(torch.load(join_path(PATH_TO_FOLDER, 'adversarial_attacks', 'facpa', 'weigths', 'unet_koncept.pth'), map_location=device))\n",
    "netG.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pPVKlwwI2Nxm",
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.chdir(join_path(PATH_TO_FOLDER, 'nr_iqa_metrics', 'KonCept512'))\n",
    "\n",
    "from inceptionresnetv2 import inceptionresnetv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8J1dd_L82LnE",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class model_qa(nn.Module):\n",
    "    def __init__(self,num_classes,**kwargs):\n",
    "        super(model_qa,self).__init__()\n",
    "        base_model = inceptionresnetv2(num_classes=1000, pretrained='imagenet')\n",
    "        self.base = nn.Sequential(*list(base_model.children())[:-1])\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(1536, 2048),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.BatchNorm1d(2048),\n",
    "            nn.Dropout(p=0.25),\n",
    "            nn.Linear(2048, 1024),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.BatchNorm1d(1024),\n",
    "            nn.Dropout(p=0.25),\n",
    "            nn.Linear(1024, 256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.BatchNorm1d(256),         \n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(256, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.base(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r4eRmaX92h1w",
    "tags": []
   },
   "outputs": [],
   "source": [
    "KonCept512 = model_qa(num_classes=1)\n",
    "KonCept512.load_state_dict(torch.load('/home/jovyan/storage/NR-metric-models/KonCept512.pth'))\n",
    "KonCept512.eval().to(device);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hTdCen-92h4D",
    "tags": []
   },
   "outputs": [],
   "source": [
    "koncept_transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Resize((384, 512)),\n",
    "        transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QujkC01YEVSd",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def img_to_batch_koncept(img):\n",
    "    batch_size_cur = 1\n",
    "    img_batch = torch.zeros(1, 3, 384, 512).to(device) \n",
    "    img_batch[0]  = koncept_transform(img) \n",
    "    # for i in range(batch_size_cur):  \n",
    "    #     img_batch[i] = koncept_transform(img) \n",
    "    return img_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 246,
     "status": "ok",
     "timestamp": 1678645387259,
     "user": {
      "displayName": "Даниил Константинов",
      "userId": "01997835485140301621"
     },
     "user_tz": -180
    },
    "id": "0CnOpVip3iGg",
    "outputId": "f08b6d0b-1123-430f-fbee-db119393ca91",
    "tags": []
   },
   "outputs": [],
   "source": [
    "C = 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1794426,
     "status": "ok",
     "timestamp": 1678648284942,
     "user": {
      "displayName": "Даниил Константинов",
      "userId": "01997835485140301621"
     },
     "user_tz": -180
    },
    "id": "ZAJMJECD3iJG",
    "outputId": "3e8c7ba0-926d-4cc0-db80-d266abd91530",
    "tags": []
   },
   "outputs": [],
   "source": [
    "res = []\n",
    "gains = []\n",
    "for image_file in tqdm(all_images):\n",
    "    image = cv2.cvtColor(cv2.imread(image_file), cv2.COLOR_BGR2RGB)\n",
    "    with torch.no_grad():\n",
    "        before_score = KonCept512(img_to_batch_koncept(image).to(device)).detach().detach().cpu().numpy()[0][0]\n",
    "\n",
    "    im = image.astype('float32') / 255.\n",
    "    h, w = im.shape[0] // RESIZE_PARAM, im.shape[1] // RESIZE_PARAM\n",
    "    if h == 0 or w == 0:\n",
    "        image = cnn_resize_256(to_tensor(im))\n",
    "        h, w = image.shape[1] // RESIZE_PARAM, image.shape[2] // RESIZE_PARAM\n",
    "        h, w = h * RESIZE_PARAM, w * RESIZE_PARAM\n",
    "        image = image[:, :h, :w]\n",
    "    else:\n",
    "        h, w = h * RESIZE_PARAM, w * RESIZE_PARAM\n",
    "        im64 = im[:h, :w, :]\n",
    "        image = to_tensor(im64)\n",
    "   \n",
    "    delta_im = netG(image.unsqueeze(0).to(device))\n",
    "    image_after_attack = add_delta_cnn(im, delta_im, h, w, C=C)\n",
    "\n",
    "    delta_im = netG(image.unsqueeze(0).to(device))\n",
    "    image_after_attack = add_delta_cnn(im, delta_im, h, w, C=C)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        after_score = KonCept512(img_to_batch_koncept(image_after_attack).to(device)).detach().detach().cpu().numpy()[0][0]\n",
    "    \n",
    "        \n",
    "    gains.append([before_score, after_score])\n",
    "    res.append([image_file.split('/')[-1], before_score, after_score])\n",
    "gains = np.array(gains)\n",
    "\n",
    "df = pd.DataFrame(res, columns=['image_name', 'before_score', 'after_score'])\n",
    "df['attack_type'] = f'cnn_{C}_255'\n",
    "df['metric'] = 'koncept'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
